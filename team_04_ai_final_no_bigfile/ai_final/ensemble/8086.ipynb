{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', 600)\n",
    "pd.set_option('display.max_rows', 600)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path  = '../data/final_data/'\n",
    "data_train = pd.read_csv(root_path+'sensor_train_final.csv')\n",
    "data_test = pd.read_csv(root_path+'sensor_test_final.csv')\n",
    "sub = pd.read_csv(root_path+'submit_example.csv')\n",
    "y = data_train.groupby('fragment_id')['behavior_id'].min()\n",
    "data_test['fragment_id'] += 100000\n",
    "label = 'behavior_id'\n",
    "data = pd.concat([data_train, data_test], sort=False,ignore_index=True)\n",
    "df = data.drop_duplicates(subset=['fragment_id']).reset_index(drop=True)[['fragment_id', 'behavior_id']]\n",
    "df[\"count\"] = data.groupby(\"fragment_id\")[\"time_point\"].count()\n",
    "\n",
    "featureList = [\"count\"]\n",
    "ans = np.zeros((16000,20))\n",
    "oof_train = np.zeros((15000,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31000, 20)\n"
     ]
    }
   ],
   "source": [
    "# LGB model\n",
    "import joblib\n",
    "# lgboof = joblib.load(\"LGB_OOF.pkl\")\n",
    "lgboof = joblib.load(\"LGB_OOF859_____5fold.pkl\")\n",
    "# lgboof = joblib.load(\"LGB_OOF859_____5foldmoremroe.pkl\")\n",
    "oof = lgboof[\"oof\"]\n",
    "preds = lgboof[\"test\"]\n",
    "ans += 0.3 * preds\n",
    "oof_train += 0.3*oof\n",
    "stack_array = np.concatenate([oof,preds],axis=0)\n",
    "print(stack_array.shape)\n",
    "for i in range(20):\n",
    "    df[\"lgb_\"+str(i)] = stack_array[:,i]\n",
    "featureList += [\"lgb_\"+str(i)for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31000, 20)\n"
     ]
    }
   ],
   "source": [
    "# LSTM model\n",
    "import joblib \n",
    "lstmoof = joblib.load(\"LSTM8370.83753_dict.pkl\")\n",
    "oof = lstmoof[\"oof\"]\n",
    "preds = lstmoof[\"test\"]\n",
    "ans += 0.3 * preds\n",
    "oof_train += 0.3*oof\n",
    "stack_array = np.concatenate([oof,preds],axis=0)\n",
    "print(stack_array.shape)\n",
    "for i in range(20):\n",
    "    df[\"lstm_\"+str(i)] = stack_array[:,i]\n",
    "featureList += [\"lstm_\"+str(i)for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31000, 20)\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "import joblib \n",
    "\n",
    "cnnoof = joblib.load(\"all_stragety-add2net0.85679_dict.pkl\")\n",
    "oof = cnnoof[\"oof\"]\n",
    "preds = cnnoof[\"test\"]\n",
    "ans += 0.4 * preds\n",
    "oof_train += 0.4*oof\n",
    "stack_array = np.concatenate([oof,preds],axis=0)\n",
    "print(stack_array.shape)\n",
    "for i in range(20):\n",
    "    df[\"CNN_\"+str(i)] = stack_array[:,i]\n",
    "featureList += [\"CNN_\"+str(i)for i in range(20)]\n",
    "\n",
    "# cnnoof = joblib.load(\"all_stragety_lcy1_0.84695_dict.pkl\")\n",
    "# oof = cnnoof[\"oof\"]\n",
    "# preds = cnnoof[\"test\"]\n",
    "\n",
    "# stack_array = np.concatenate([oof,preds],axis=0)\n",
    "# print(stack_array.shape)\n",
    "# for i in range(20):\n",
    "#     df[\"CNN_\"+str(i)] = stack_array[:,i]\n",
    "# featureList += [\"CNN_\"+str(i)for i in range(20)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31000, 20)\n"
     ]
    }
   ],
   "source": [
    "stack_array = np.concatenate([oof_train,ans],axis=0)\n",
    "print(stack_array.shape)\n",
    "for i in range(20):\n",
    "    df[\"blending\"+str(i)] = stack_array[:,i]\n",
    "featureList += [\"blending\"+str(i)for i in range(20)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87327\n",
      "0.88871\n"
     ]
    }
   ],
   "source": [
    "# def acc_combo(y, y_pred):\n",
    "#     # 数值ID与行为编码的对应关系\n",
    "#     mapping = {\n",
    "#         '0': 'A_1', '1': 'B_2', '2': 'A_3', '3': 'A_4', '4': 'B_3', '5': 'C_5', '6': 'C_2', '7': 'A_5', '8': 'B_1', \n",
    "#         '9': 'C_1', '10': 'A_2', '11': 'C_3', '12': 'B_5', '13': 'B_4', '14': 'C_4', \n",
    "#         '15': 'D_6', '16': 'E_7', '17': 'F_8', '18': 'G_9', '19': 'H_0'\n",
    "#               }\n",
    "#     # 将行为ID转为编码\n",
    "#     code_y, code_y_pred = mapping[str(int(y))], mapping[str(int(y_pred))]\n",
    "#     if code_y == code_y_pred: #编码完全相同得分1.0\n",
    "#         return 1.0\n",
    "#     elif code_y.split(\"_\")[0] == code_y_pred.split(\"_\")[0]: #编码仅字母部分相同得分1.0/7\n",
    "#         return 1.0/7\n",
    "#     elif code_y.split(\"_\")[1] == code_y_pred.split(\"_\")[1]: #编码仅数字部分相同得分1.0/3\n",
    "#         return 1.0/3\n",
    "#     else:\n",
    "#         return 0.0\n",
    "\n",
    "# df = df.fillna(0)\n",
    "# df.loc[:15000,\"istrain\"] = 1\n",
    "# df.loc[15000:,\"istrain\"] = 0\n",
    "\n",
    "# train_df = df[df[\"istrain\"]==1].reset_index(drop=True)\n",
    "# test_df = df[df[\"istrain\"]==0].reset_index(drop=True)\n",
    "# train_y = train_df[label]\n",
    "# labels = np.argmax(ans, axis=1)\n",
    "# oof_y = np.argmax(oof_train, axis=1)\n",
    "# print(round(accuracy_score(train_y, oof_y), 5))\n",
    "# score = sum(acc_combo(y_true, y_pred) for y_true, y_pred in zip(train_y, oof_y)) / oof_y.shape[0]\n",
    "# print(round(score, 5))\n",
    "# sub = pd.read_csv(root_path+'submit_example.csv')\n",
    "\n",
    "# sub['behavior_id'] = labels\n",
    "\n",
    "# vc = data_train['behavior_id'].value_counts().sort_index()\n",
    "# sns.barplot(vc.index, vc.values)\n",
    "# plt.show()\n",
    "# vc = sub['behavior_id'].value_counts().sort_index()\n",
    "# sns.barplot(vc.index, vc.values)\n",
    "# plt.show()\n",
    "# sub.to_csv('blending%.5f.csv' % score, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "['count', 'lgb_0', 'lgb_1', 'lgb_2', 'lgb_3', 'lgb_4', 'lgb_5', 'lgb_6', 'lgb_7', 'lgb_8', 'lgb_9', 'lgb_10', 'lgb_11', 'lgb_12', 'lgb_13', 'lgb_14', 'lgb_15', 'lgb_16', 'lgb_17', 'lgb_18', 'lgb_19', 'lstm_0', 'lstm_1', 'lstm_2', 'lstm_3', 'lstm_4', 'lstm_5', 'lstm_6', 'lstm_7', 'lstm_8', 'lstm_9', 'lstm_10', 'lstm_11', 'lstm_12', 'lstm_13', 'lstm_14', 'lstm_15', 'lstm_16', 'lstm_17', 'lstm_18', 'lstm_19', 'CNN_0', 'CNN_1', 'CNN_2', 'CNN_3', 'CNN_4', 'CNN_5', 'CNN_6', 'CNN_7', 'CNN_8', 'CNN_9', 'CNN_10', 'CNN_11', 'CNN_12', 'CNN_13', 'CNN_14', 'CNN_15', 'CNN_16', 'CNN_17', 'CNN_18', 'CNN_19', 'blending0', 'blending1', 'blending2', 'blending3', 'blending4', 'blending5', 'blending6', 'blending7', 'blending8', 'blending9', 'blending10', 'blending11', 'blending12', 'blending13', 'blending14', 'blending15', 'blending16', 'blending17', 'blending18', 'blending19']\n",
      "\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0779167\tvalid_1's multi_error: 0.110667\n",
      "[40]\ttraining's multi_error: 0.0573333\tvalid_1's multi_error: 0.111\n",
      "[60]\ttraining's multi_error: 0.0381667\tvalid_1's multi_error: 0.109\n",
      "[80]\ttraining's multi_error: 0.0235833\tvalid_1's multi_error: 0.108333\n",
      "[100]\ttraining's multi_error: 0.01125\tvalid_1's multi_error: 0.108333\n",
      "[120]\ttraining's multi_error: 0.005\tvalid_1's multi_error: 0.109333\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's multi_error: 0.0285\tvalid_1's multi_error: 0.107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6497"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0740833\tvalid_1's multi_error: 0.120667\n",
      "[40]\ttraining's multi_error: 0.0570833\tvalid_1's multi_error: 0.119667\n",
      "[60]\ttraining's multi_error: 0.03875\tvalid_1's multi_error: 0.118333\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's multi_error: 0.0791667\tvalid_1's multi_error: 0.118333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0738333\tvalid_1's multi_error: 0.115667\n",
      "[40]\ttraining's multi_error: 0.0561667\tvalid_1's multi_error: 0.116667\n",
      "[60]\ttraining's multi_error: 0.0391667\tvalid_1's multi_error: 0.117\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's multi_error: 0.0669167\tvalid_1's multi_error: 0.114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6280"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0739167\tvalid_1's multi_error: 0.129667\n",
      "[40]\ttraining's multi_error: 0.0549167\tvalid_1's multi_error: 0.130333\n",
      "[60]\ttraining's multi_error: 0.0370833\tvalid_1's multi_error: 0.128667\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's multi_error: 0.08025\tvalid_1's multi_error: 0.126333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0738333\tvalid_1's multi_error: 0.123667\n",
      "[40]\ttraining's multi_error: 0.0559167\tvalid_1's multi_error: 0.122\n",
      "[60]\ttraining's multi_error: 0.0376667\tvalid_1's multi_error: 0.121667\n",
      "[80]\ttraining's multi_error: 0.0221667\tvalid_1's multi_error: 0.122667\n",
      "[100]\ttraining's multi_error: 0.0106667\tvalid_1's multi_error: 0.123333\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's multi_error: 0.0386667\tvalid_1's multi_error: 0.120333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0729167\tvalid_1's multi_error: 0.116667\n",
      "[40]\ttraining's multi_error: 0.0551667\tvalid_1's multi_error: 0.115667\n",
      "[60]\ttraining's multi_error: 0.0375833\tvalid_1's multi_error: 0.115667\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's multi_error: 0.06625\tvalid_1's multi_error: 0.114333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0735\tvalid_1's multi_error: 0.122\n",
      "[40]\ttraining's multi_error: 0.0555\tvalid_1's multi_error: 0.123\n",
      "[60]\ttraining's multi_error: 0.039\tvalid_1's multi_error: 0.121\n",
      "[80]\ttraining's multi_error: 0.0224167\tvalid_1's multi_error: 0.12\n",
      "[100]\ttraining's multi_error: 0.01175\tvalid_1's multi_error: 0.122333\n",
      "[120]\ttraining's multi_error: 0.00541667\tvalid_1's multi_error: 0.122\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's multi_error: 0.0224167\tvalid_1's multi_error: 0.12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0746667\tvalid_1's multi_error: 0.111333\n",
      "[40]\ttraining's multi_error: 0.0573333\tvalid_1's multi_error: 0.108667\n",
      "[60]\ttraining's multi_error: 0.03925\tvalid_1's multi_error: 0.111\n",
      "[80]\ttraining's multi_error: 0.0229167\tvalid_1's multi_error: 0.111333\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's multi_error: 0.0615\tvalid_1's multi_error: 0.108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0764167\tvalid_1's multi_error: 0.119333\n",
      "[40]\ttraining's multi_error: 0.0585833\tvalid_1's multi_error: 0.12\n",
      "[60]\ttraining's multi_error: 0.0391667\tvalid_1's multi_error: 0.121333\n",
      "[80]\ttraining's multi_error: 0.0220833\tvalid_1's multi_error: 0.118333\n",
      "[100]\ttraining's multi_error: 0.011\tvalid_1's multi_error: 0.117667\n",
      "[120]\ttraining's multi_error: 0.0045\tvalid_1's multi_error: 0.117\n",
      "[140]\ttraining's multi_error: 0.00191667\tvalid_1's multi_error: 0.117\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's multi_error: 0.007\tvalid_1's multi_error: 0.116333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0755\tvalid_1's multi_error: 0.123667\n",
      "[40]\ttraining's multi_error: 0.0576667\tvalid_1's multi_error: 0.122\n",
      "[60]\ttraining's multi_error: 0.04\tvalid_1's multi_error: 0.121667\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's multi_error: 0.0668333\tvalid_1's multi_error: 0.121333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.07375\tvalid_1's multi_error: 0.119\n",
      "[40]\ttraining's multi_error: 0.05475\tvalid_1's multi_error: 0.12\n",
      "[60]\ttraining's multi_error: 0.0375\tvalid_1's multi_error: 0.119667\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's multi_error: 0.0719167\tvalid_1's multi_error: 0.117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0769167\tvalid_1's multi_error: 0.121333\n",
      "[40]\ttraining's multi_error: 0.05775\tvalid_1's multi_error: 0.119333\n",
      "[60]\ttraining's multi_error: 0.0394167\tvalid_1's multi_error: 0.118667\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_error: 0.0725\tvalid_1's multi_error: 0.118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0745\tvalid_1's multi_error: 0.120667\n",
      "[40]\ttraining's multi_error: 0.0550833\tvalid_1's multi_error: 0.122\n",
      "[60]\ttraining's multi_error: 0.0373333\tvalid_1's multi_error: 0.121667\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_error: 0.0685\tvalid_1's multi_error: 0.118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0745\tvalid_1's multi_error: 0.113333\n",
      "[40]\ttraining's multi_error: 0.0566667\tvalid_1's multi_error: 0.111667\n",
      "[60]\ttraining's multi_error: 0.0398333\tvalid_1's multi_error: 0.111667\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's multi_error: 0.0786667\tvalid_1's multi_error: 0.110667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0754167\tvalid_1's multi_error: 0.121\n",
      "[40]\ttraining's multi_error: 0.0581667\tvalid_1's multi_error: 0.119\n",
      "[60]\ttraining's multi_error: 0.0389167\tvalid_1's multi_error: 0.122\n",
      "[80]\ttraining's multi_error: 0.02375\tvalid_1's multi_error: 0.121667\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's multi_error: 0.05925\tvalid_1's multi_error: 0.118333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.07625\tvalid_1's multi_error: 0.108\n",
      "[40]\ttraining's multi_error: 0.0575833\tvalid_1's multi_error: 0.108333\n",
      "[60]\ttraining's multi_error: 0.0388333\tvalid_1's multi_error: 0.112\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's multi_error: 0.0785\tvalid_1's multi_error: 0.108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0725\tvalid_1's multi_error: 0.119\n",
      "[40]\ttraining's multi_error: 0.0556667\tvalid_1's multi_error: 0.118333\n",
      "[60]\ttraining's multi_error: 0.0375\tvalid_1's multi_error: 0.115667\n",
      "[80]\ttraining's multi_error: 0.0223333\tvalid_1's multi_error: 0.116333\n",
      "[100]\ttraining's multi_error: 0.0110833\tvalid_1's multi_error: 0.115\n",
      "[120]\ttraining's multi_error: 0.00583333\tvalid_1's multi_error: 0.115333\n",
      "[140]\ttraining's multi_error: 0.00308333\tvalid_1's multi_error: 0.115667\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's multi_error: 0.0114167\tvalid_1's multi_error: 0.114333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0765\tvalid_1's multi_error: 0.116333\n",
      "[40]\ttraining's multi_error: 0.0595\tvalid_1's multi_error: 0.116\n",
      "[60]\ttraining's multi_error: 0.03725\tvalid_1's multi_error: 0.116667\n",
      "[80]\ttraining's multi_error: 0.02225\tvalid_1's multi_error: 0.117\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's multi_error: 0.0679167\tvalid_1's multi_error: 0.114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.075\tvalid_1's multi_error: 0.116333\n",
      "[40]\ttraining's multi_error: 0.0588333\tvalid_1's multi_error: 0.119\n",
      "[60]\ttraining's multi_error: 0.0400833\tvalid_1's multi_error: 0.119\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's multi_error: 0.079\tvalid_1's multi_error: 0.116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0739167\tvalid_1's multi_error: 0.127333\n",
      "[40]\ttraining's multi_error: 0.0548333\tvalid_1's multi_error: 0.125333\n",
      "[60]\ttraining's multi_error: 0.0366667\tvalid_1's multi_error: 0.122667\n",
      "[80]\ttraining's multi_error: 0.0219167\tvalid_1's multi_error: 0.123\n",
      "[100]\ttraining's multi_error: 0.0106667\tvalid_1's multi_error: 0.124333\n",
      "[120]\ttraining's multi_error: 0.00483333\tvalid_1's multi_error: 0.124\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's multi_error: 0.0275\tvalid_1's multi_error: 0.121333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>blending7</td>\n",
       "      <td>28273.005058</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>blending12</td>\n",
       "      <td>24143.943029</td>\n",
       "      <td>1557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>blending5</td>\n",
       "      <td>19428.985518</td>\n",
       "      <td>1476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lgb_16</td>\n",
       "      <td>18981.496178</td>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>blending4</td>\n",
       "      <td>17040.529183</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>blending13</td>\n",
       "      <td>16272.038655</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>blending8</td>\n",
       "      <td>16044.367018</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lgb_15</td>\n",
       "      <td>14648.533917</td>\n",
       "      <td>1804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>blending0</td>\n",
       "      <td>13381.875522</td>\n",
       "      <td>1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>blending1</td>\n",
       "      <td>13204.624393</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>blending2</td>\n",
       "      <td>12896.258545</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>blending3</td>\n",
       "      <td>12669.306413</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lgb_19</td>\n",
       "      <td>12461.450269</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>blending11</td>\n",
       "      <td>11983.913839</td>\n",
       "      <td>1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>CNN_19</td>\n",
       "      <td>11821.307732</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>blending18</td>\n",
       "      <td>10937.721633</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>blending9</td>\n",
       "      <td>10644.718929</td>\n",
       "      <td>1317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lstm_19</td>\n",
       "      <td>10546.239578</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>blending17</td>\n",
       "      <td>9706.331927</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lgb_18</td>\n",
       "      <td>8582.590031</td>\n",
       "      <td>1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>blending14</td>\n",
       "      <td>8493.676337</td>\n",
       "      <td>1479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>blending6</td>\n",
       "      <td>7772.991043</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>CNN_14</td>\n",
       "      <td>6333.025368</td>\n",
       "      <td>1514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lgb_17</td>\n",
       "      <td>6058.865138</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>CNN_9</td>\n",
       "      <td>5429.880059</td>\n",
       "      <td>1318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>blending10</td>\n",
       "      <td>5359.608024</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>blending15</td>\n",
       "      <td>5312.934909</td>\n",
       "      <td>1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>CNN_11</td>\n",
       "      <td>5092.180342</td>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>CNN_0</td>\n",
       "      <td>5038.219603</td>\n",
       "      <td>1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lgb_0</td>\n",
       "      <td>4825.467844</td>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgb_1</td>\n",
       "      <td>4748.627054</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lgb_6</td>\n",
       "      <td>4533.379959</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lgb_8</td>\n",
       "      <td>4069.166842</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CNN_5</td>\n",
       "      <td>4045.370499</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lgb_10</td>\n",
       "      <td>3184.765182</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lgb_13</td>\n",
       "      <td>3023.863138</td>\n",
       "      <td>1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>blending19</td>\n",
       "      <td>2943.466024</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CNN_3</td>\n",
       "      <td>2937.960407</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lgb_14</td>\n",
       "      <td>2902.215732</td>\n",
       "      <td>1453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgb_2</td>\n",
       "      <td>2866.348230</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lgb_12</td>\n",
       "      <td>2684.315390</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CNN_4</td>\n",
       "      <td>2512.226417</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>blending16</td>\n",
       "      <td>2229.744738</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CNN_18</td>\n",
       "      <td>2193.477113</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lstm_8</td>\n",
       "      <td>2036.308392</td>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgb_3</td>\n",
       "      <td>1649.345126</td>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CNN_2</td>\n",
       "      <td>1581.784439</td>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>CNN_7</td>\n",
       "      <td>1539.512574</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>CNN_15</td>\n",
       "      <td>1526.054754</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lstm_4</td>\n",
       "      <td>1501.408162</td>\n",
       "      <td>1133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CNN_12</td>\n",
       "      <td>1456.590056</td>\n",
       "      <td>1684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgb_5</td>\n",
       "      <td>1446.517470</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>lstm_18</td>\n",
       "      <td>1393.284383</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgb_4</td>\n",
       "      <td>1374.159322</td>\n",
       "      <td>1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>CNN_10</td>\n",
       "      <td>1339.975218</td>\n",
       "      <td>1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>lstm_14</td>\n",
       "      <td>1196.261235</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lgb_9</td>\n",
       "      <td>1131.219042</td>\n",
       "      <td>1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>lstm_13</td>\n",
       "      <td>1121.496653</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CNN_16</td>\n",
       "      <td>1108.654562</td>\n",
       "      <td>1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lgb_11</td>\n",
       "      <td>1090.914523</td>\n",
       "      <td>1186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lstm_9</td>\n",
       "      <td>1003.018453</td>\n",
       "      <td>1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>lstm_17</td>\n",
       "      <td>923.687112</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>CNN_13</td>\n",
       "      <td>878.253999</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>CNN_1</td>\n",
       "      <td>846.030428</td>\n",
       "      <td>1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>CNN_17</td>\n",
       "      <td>840.311867</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CNN_6</td>\n",
       "      <td>834.429966</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lstm_0</td>\n",
       "      <td>794.330447</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lgb_7</td>\n",
       "      <td>745.605404</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lstm_15</td>\n",
       "      <td>689.799076</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lstm_3</td>\n",
       "      <td>613.994142</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lstm_6</td>\n",
       "      <td>538.812164</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lstm_12</td>\n",
       "      <td>537.862676</td>\n",
       "      <td>1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lstm_2</td>\n",
       "      <td>517.509781</td>\n",
       "      <td>1518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lstm_5</td>\n",
       "      <td>494.169247</td>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lstm_1</td>\n",
       "      <td>490.285638</td>\n",
       "      <td>1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CNN_8</td>\n",
       "      <td>478.098285</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>lstm_11</td>\n",
       "      <td>472.943580</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lstm_10</td>\n",
       "      <td>452.075392</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>lstm_16</td>\n",
       "      <td>433.897888</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lstm_7</td>\n",
       "      <td>346.377650</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>243.876566</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feat          gain  split\n",
       "68   blending7  28273.005058   1509\n",
       "73  blending12  24143.943029   1557\n",
       "66   blending5  19428.985518   1476\n",
       "17      lgb_16  18981.496178   1375\n",
       "65   blending4  17040.529183   1374\n",
       "74  blending13  16272.038655   1389\n",
       "69   blending8  16044.367018   1176\n",
       "16      lgb_15  14648.533917   1804\n",
       "61   blending0  13381.875522   1104\n",
       "62   blending1  13204.624393   1120\n",
       "63   blending2  12896.258545   1236\n",
       "64   blending3  12669.306413   1313\n",
       "20      lgb_19  12461.450269    668\n",
       "72  blending11  11983.913839   1266\n",
       "60      CNN_19  11821.307732    753\n",
       "79  blending18  10937.721633   1252\n",
       "70   blending9  10644.718929   1317\n",
       "40     lstm_19  10546.239578    837\n",
       "78  blending17   9706.331927   1228\n",
       "19      lgb_18   8582.590031   1301\n",
       "75  blending14   8493.676337   1479\n",
       "67   blending6   7772.991043   1071\n",
       "55      CNN_14   6333.025368   1514\n",
       "18      lgb_17   6058.865138   1149\n",
       "50       CNN_9   5429.880059   1318\n",
       "71  blending10   5359.608024   1249\n",
       "76  blending15   5312.934909   1432\n",
       "52      CNN_11   5092.180342   1446\n",
       "41       CNN_0   5038.219603   1172\n",
       "1        lgb_0   4825.467844   1077\n",
       "2        lgb_1   4748.627054   1268\n",
       "7        lgb_6   4533.379959   1166\n",
       "9        lgb_8   4069.166842   1143\n",
       "46       CNN_5   4045.370499   1452\n",
       "11      lgb_10   3184.765182   1389\n",
       "14      lgb_13   3023.863138   1486\n",
       "80  blending19   2943.466024    650\n",
       "44       CNN_3   2937.960407   1217\n",
       "15      lgb_14   2902.215732   1453\n",
       "3        lgb_2   2866.348230   1281\n",
       "13      lgb_12   2684.315390   1531\n",
       "45       CNN_4   2512.226417   1188\n",
       "77  blending16   2229.744738   1210\n",
       "59      CNN_18   2193.477113   1268\n",
       "29      lstm_8   2036.308392   1205\n",
       "4        lgb_3   1649.345126   1278\n",
       "43       CNN_2   1581.784439   1402\n",
       "48       CNN_7   1539.512574   1303\n",
       "56      CNN_15   1526.054754   1419\n",
       "25      lstm_4   1501.408162   1133\n",
       "53      CNN_12   1456.590056   1684\n",
       "6        lgb_5   1446.517470   1270\n",
       "39     lstm_18   1393.284383   1305\n",
       "5        lgb_4   1374.159322   1118\n",
       "51      CNN_10   1339.975218   1111\n",
       "35     lstm_14   1196.261235   1346\n",
       "10       lgb_9   1131.219042   1330\n",
       "34     lstm_13   1121.496653   1237\n",
       "57      CNN_16   1108.654562   1167\n",
       "12      lgb_11   1090.914523   1186\n",
       "30      lstm_9   1003.018453   1577\n",
       "38     lstm_17    923.687112   1374\n",
       "54      CNN_13    878.253999   1166\n",
       "42       CNN_1    846.030428   1167\n",
       "58      CNN_17    840.311867   1294\n",
       "47       CNN_6    834.429966   1290\n",
       "21      lstm_0    794.330447   1236\n",
       "8        lgb_7    745.605404   1176\n",
       "36     lstm_15    689.799076   1373\n",
       "24      lstm_3    613.994142   1241\n",
       "27      lstm_6    538.812164   1281\n",
       "33     lstm_12    537.862676   1334\n",
       "23      lstm_2    517.509781   1518\n",
       "26      lstm_5    494.169247   1491\n",
       "22      lstm_1    490.285638   1308\n",
       "49       CNN_8    478.098285   1217\n",
       "32     lstm_11    472.943580   1281\n",
       "31     lstm_10    452.075392   1419\n",
       "37     lstm_16    433.897888   1085\n",
       "28      lstm_7    346.377650   1110\n",
       "0        count    243.876566    815"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lgb_15</td>\n",
       "      <td>14648.533917</td>\n",
       "      <td>1804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CNN_12</td>\n",
       "      <td>1456.590056</td>\n",
       "      <td>1684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lstm_9</td>\n",
       "      <td>1003.018453</td>\n",
       "      <td>1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>blending12</td>\n",
       "      <td>24143.943029</td>\n",
       "      <td>1557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lgb_12</td>\n",
       "      <td>2684.315390</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lstm_2</td>\n",
       "      <td>517.509781</td>\n",
       "      <td>1518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>CNN_14</td>\n",
       "      <td>6333.025368</td>\n",
       "      <td>1514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>blending7</td>\n",
       "      <td>28273.005058</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lstm_5</td>\n",
       "      <td>494.169247</td>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lgb_13</td>\n",
       "      <td>3023.863138</td>\n",
       "      <td>1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>blending14</td>\n",
       "      <td>8493.676337</td>\n",
       "      <td>1479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>blending5</td>\n",
       "      <td>19428.985518</td>\n",
       "      <td>1476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lgb_14</td>\n",
       "      <td>2902.215732</td>\n",
       "      <td>1453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CNN_5</td>\n",
       "      <td>4045.370499</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>CNN_11</td>\n",
       "      <td>5092.180342</td>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>blending15</td>\n",
       "      <td>5312.934909</td>\n",
       "      <td>1432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lstm_10</td>\n",
       "      <td>452.075392</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>CNN_15</td>\n",
       "      <td>1526.054754</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CNN_2</td>\n",
       "      <td>1581.784439</td>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lgb_10</td>\n",
       "      <td>3184.765182</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>blending13</td>\n",
       "      <td>16272.038655</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lgb_16</td>\n",
       "      <td>18981.496178</td>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>blending4</td>\n",
       "      <td>17040.529183</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>lstm_17</td>\n",
       "      <td>923.687112</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lstm_15</td>\n",
       "      <td>689.799076</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>lstm_14</td>\n",
       "      <td>1196.261235</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lstm_12</td>\n",
       "      <td>537.862676</td>\n",
       "      <td>1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lgb_9</td>\n",
       "      <td>1131.219042</td>\n",
       "      <td>1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>CNN_9</td>\n",
       "      <td>5429.880059</td>\n",
       "      <td>1318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>blending9</td>\n",
       "      <td>10644.718929</td>\n",
       "      <td>1317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>blending3</td>\n",
       "      <td>12669.306413</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lstm_1</td>\n",
       "      <td>490.285638</td>\n",
       "      <td>1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>lstm_18</td>\n",
       "      <td>1393.284383</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>CNN_7</td>\n",
       "      <td>1539.512574</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lgb_18</td>\n",
       "      <td>8582.590031</td>\n",
       "      <td>1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>CNN_17</td>\n",
       "      <td>840.311867</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CNN_6</td>\n",
       "      <td>834.429966</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>lstm_11</td>\n",
       "      <td>472.943580</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lstm_6</td>\n",
       "      <td>538.812164</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgb_2</td>\n",
       "      <td>2866.348230</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgb_3</td>\n",
       "      <td>1649.345126</td>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgb_5</td>\n",
       "      <td>1446.517470</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgb_1</td>\n",
       "      <td>4748.627054</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CNN_18</td>\n",
       "      <td>2193.477113</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>blending11</td>\n",
       "      <td>11983.913839</td>\n",
       "      <td>1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>blending18</td>\n",
       "      <td>10937.721633</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>blending10</td>\n",
       "      <td>5359.608024</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lstm_3</td>\n",
       "      <td>613.994142</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>lstm_13</td>\n",
       "      <td>1121.496653</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>blending2</td>\n",
       "      <td>12896.258545</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lstm_0</td>\n",
       "      <td>794.330447</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>blending17</td>\n",
       "      <td>9706.331927</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CNN_8</td>\n",
       "      <td>478.098285</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CNN_3</td>\n",
       "      <td>2937.960407</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>blending16</td>\n",
       "      <td>2229.744738</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lstm_8</td>\n",
       "      <td>2036.308392</td>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CNN_4</td>\n",
       "      <td>2512.226417</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lgb_11</td>\n",
       "      <td>1090.914523</td>\n",
       "      <td>1186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>blending8</td>\n",
       "      <td>16044.367018</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lgb_7</td>\n",
       "      <td>745.605404</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>CNN_0</td>\n",
       "      <td>5038.219603</td>\n",
       "      <td>1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CNN_16</td>\n",
       "      <td>1108.654562</td>\n",
       "      <td>1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>CNN_1</td>\n",
       "      <td>846.030428</td>\n",
       "      <td>1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>CNN_13</td>\n",
       "      <td>878.253999</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lgb_6</td>\n",
       "      <td>4533.379959</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lgb_17</td>\n",
       "      <td>6058.865138</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lgb_8</td>\n",
       "      <td>4069.166842</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lstm_4</td>\n",
       "      <td>1501.408162</td>\n",
       "      <td>1133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>blending1</td>\n",
       "      <td>13204.624393</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgb_4</td>\n",
       "      <td>1374.159322</td>\n",
       "      <td>1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>CNN_10</td>\n",
       "      <td>1339.975218</td>\n",
       "      <td>1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lstm_7</td>\n",
       "      <td>346.377650</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>blending0</td>\n",
       "      <td>13381.875522</td>\n",
       "      <td>1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>lstm_16</td>\n",
       "      <td>433.897888</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lgb_0</td>\n",
       "      <td>4825.467844</td>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>blending6</td>\n",
       "      <td>7772.991043</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lstm_19</td>\n",
       "      <td>10546.239578</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>243.876566</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>CNN_19</td>\n",
       "      <td>11821.307732</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lgb_19</td>\n",
       "      <td>12461.450269</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>blending19</td>\n",
       "      <td>2943.466024</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feat          gain  split\n",
       "16      lgb_15  14648.533917   1804\n",
       "53      CNN_12   1456.590056   1684\n",
       "30      lstm_9   1003.018453   1577\n",
       "73  blending12  24143.943029   1557\n",
       "13      lgb_12   2684.315390   1531\n",
       "23      lstm_2    517.509781   1518\n",
       "55      CNN_14   6333.025368   1514\n",
       "68   blending7  28273.005058   1509\n",
       "26      lstm_5    494.169247   1491\n",
       "14      lgb_13   3023.863138   1486\n",
       "75  blending14   8493.676337   1479\n",
       "66   blending5  19428.985518   1476\n",
       "15      lgb_14   2902.215732   1453\n",
       "46       CNN_5   4045.370499   1452\n",
       "52      CNN_11   5092.180342   1446\n",
       "76  blending15   5312.934909   1432\n",
       "31     lstm_10    452.075392   1419\n",
       "56      CNN_15   1526.054754   1419\n",
       "43       CNN_2   1581.784439   1402\n",
       "11      lgb_10   3184.765182   1389\n",
       "74  blending13  16272.038655   1389\n",
       "17      lgb_16  18981.496178   1375\n",
       "65   blending4  17040.529183   1374\n",
       "38     lstm_17    923.687112   1374\n",
       "36     lstm_15    689.799076   1373\n",
       "35     lstm_14   1196.261235   1346\n",
       "33     lstm_12    537.862676   1334\n",
       "10       lgb_9   1131.219042   1330\n",
       "50       CNN_9   5429.880059   1318\n",
       "70   blending9  10644.718929   1317\n",
       "64   blending3  12669.306413   1313\n",
       "22      lstm_1    490.285638   1308\n",
       "39     lstm_18   1393.284383   1305\n",
       "48       CNN_7   1539.512574   1303\n",
       "19      lgb_18   8582.590031   1301\n",
       "58      CNN_17    840.311867   1294\n",
       "47       CNN_6    834.429966   1290\n",
       "32     lstm_11    472.943580   1281\n",
       "27      lstm_6    538.812164   1281\n",
       "3        lgb_2   2866.348230   1281\n",
       "4        lgb_3   1649.345126   1278\n",
       "6        lgb_5   1446.517470   1270\n",
       "2        lgb_1   4748.627054   1268\n",
       "59      CNN_18   2193.477113   1268\n",
       "72  blending11  11983.913839   1266\n",
       "79  blending18  10937.721633   1252\n",
       "71  blending10   5359.608024   1249\n",
       "24      lstm_3    613.994142   1241\n",
       "34     lstm_13   1121.496653   1237\n",
       "63   blending2  12896.258545   1236\n",
       "21      lstm_0    794.330447   1236\n",
       "78  blending17   9706.331927   1228\n",
       "49       CNN_8    478.098285   1217\n",
       "44       CNN_3   2937.960407   1217\n",
       "77  blending16   2229.744738   1210\n",
       "29      lstm_8   2036.308392   1205\n",
       "45       CNN_4   2512.226417   1188\n",
       "12      lgb_11   1090.914523   1186\n",
       "69   blending8  16044.367018   1176\n",
       "8        lgb_7    745.605404   1176\n",
       "41       CNN_0   5038.219603   1172\n",
       "57      CNN_16   1108.654562   1167\n",
       "42       CNN_1    846.030428   1167\n",
       "54      CNN_13    878.253999   1166\n",
       "7        lgb_6   4533.379959   1166\n",
       "18      lgb_17   6058.865138   1149\n",
       "9        lgb_8   4069.166842   1143\n",
       "25      lstm_4   1501.408162   1133\n",
       "62   blending1  13204.624393   1120\n",
       "5        lgb_4   1374.159322   1118\n",
       "51      CNN_10   1339.975218   1111\n",
       "28      lstm_7    346.377650   1110\n",
       "61   blending0  13381.875522   1104\n",
       "37     lstm_16    433.897888   1085\n",
       "1        lgb_0   4825.467844   1077\n",
       "67   blending6   7772.991043   1071\n",
       "40     lstm_19  10546.239578    837\n",
       "0        count    243.876566    815\n",
       "60      CNN_19  11821.307732    753\n",
       "20      lgb_19  12461.450269    668\n",
       "80  blending19   2943.466024    650"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(0)\n",
    "df.loc[:15000,\"istrain\"] = 1\n",
    "df.loc[15000:,\"istrain\"] = 0\n",
    "\n",
    "train_df = df[df[\"istrain\"]==1].reset_index(drop=True)\n",
    "test_df = df[df[\"istrain\"]==0].reset_index(drop=True)\n",
    "\n",
    "drop_feat = [\"istrain\"]\n",
    "used_feat = [f for f in train_df.columns if f not in (['fragment_id', label] + drop_feat)]\n",
    "print(len(used_feat))\n",
    "print(used_feat)\n",
    "\n",
    "train_x = train_df[used_feat]\n",
    "train_y = train_df[label]\n",
    "test_x = test_df[used_feat]\n",
    "print()\n",
    "\n",
    "scores = []\n",
    "imp = pd.DataFrame()\n",
    "imp['feat'] = used_feat\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'metric': 'multi_error',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 20,\n",
    "    'feature_fraction': 0.80,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 2,\n",
    "    'n_jobs': 4,\n",
    "    'seed': 2020,\n",
    "    'max_depth': 10,\n",
    "    'num_leaves': 64,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 0.5,\n",
    "}\n",
    "\n",
    "oof_train = np.zeros((len(train_x), 20))\n",
    "preds = np.zeros((len(test_x), 20))\n",
    "folds = 5\n",
    "seeds = [44, 2020, 527, 1527]\n",
    "for seed in seeds:\n",
    "    kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        x_trn, y_trn, x_val, y_val = train_x.iloc[trn_idx], train_y.iloc[trn_idx], train_x.iloc[val_idx], train_y.iloc[val_idx]\n",
    "        train_set = lgb.Dataset(x_trn, y_trn)\n",
    "        val_set = lgb.Dataset(x_val, y_val)\n",
    "\n",
    "        model = lgb.train(params, train_set, num_boost_round=500000,\n",
    "                          valid_sets=(train_set, val_set), early_stopping_rounds=50,\n",
    "                          verbose_eval=20)\n",
    "        oof_train[val_idx] += model.predict(x_val) / len(seeds)\n",
    "        preds += model.predict(test_x) / folds / len(seeds)\n",
    "        scores.append(model.best_score['valid_1']['multi_error'])\n",
    "        imp['gain' + str(fold + 1)] = model.feature_importance(importance_type='gain')\n",
    "        imp['split' + str(fold + 1)] = model.feature_importance(importance_type='split')\n",
    "        del x_trn, y_trn, x_val, y_val, model, train_set, val_set\n",
    "        gc.collect()\n",
    "imp['gain'] = imp[[f for f in imp.columns if 'gain' in f]].sum(axis=1)/folds\n",
    "imp['split'] = imp[[f for f in imp.columns if 'split' in f]].sum(axis=1)\n",
    "imp = imp.sort_values(by=['gain'], ascending=False)\n",
    "imp[['feat', 'gain', 'split']]\n",
    "imp = imp.sort_values(by=['split'], ascending=False)\n",
    "imp[['feat', 'gain', 'split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88333\n",
      "0.89898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f88314e13d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f883143d390>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def acc_combo(y, y_pred):\n",
    "    # 数值ID与行为编码的对应关系\n",
    "    mapping = {\n",
    "        '0': 'A_1', '1': 'B_2', '2': 'A_3', '3': 'A_4', '4': 'B_3', '5': 'C_5', '6': 'C_2', '7': 'A_5', '8': 'B_1', \n",
    "        '9': 'C_1', '10': 'A_2', '11': 'C_3', '12': 'B_5', '13': 'B_4', '14': 'C_4', \n",
    "        '15': 'D_6', '16': 'E_7', '17': 'F_8', '18': 'G_9', '19': 'H_0'\n",
    "              }\n",
    "    # 将行为ID转为编码\n",
    "    code_y, code_y_pred = mapping[str(int(y))], mapping[str(int(y_pred))]\n",
    "    if code_y == code_y_pred: #编码完全相同得分1.0\n",
    "        return 1.0\n",
    "    elif code_y.split(\"_\")[0] == code_y_pred.split(\"_\")[0]: #编码仅字母部分相同得分1.0/7\n",
    "        return 1.0/7\n",
    "    elif code_y.split(\"_\")[1] == code_y_pred.split(\"_\")[1]: #编码仅数字部分相同得分1.0/3\n",
    "        return 1.0/3\n",
    "    else:\n",
    "        return 0.0\n",
    "labels = np.argmax(preds, axis=1)\n",
    "oof_y = np.argmax(oof_train, axis=1)\n",
    "print(round(accuracy_score(train_y, oof_y), 5))\n",
    "score = sum(acc_combo(y_true, y_pred) for y_true, y_pred in zip(train_y, oof_y)) / oof_y.shape[0]\n",
    "print(round(score, 5))\n",
    "\n",
    "sub = pd.read_csv(root_path+'submit_example.csv')\n",
    "\n",
    "sub['behavior_id'] = labels\n",
    "\n",
    "vc = data_train['behavior_id'].value_counts().sort_index()\n",
    "sns.barplot(vc.index, vc.values)\n",
    "plt.show()\n",
    "vc = sub['behavior_id'].value_counts().sort_index()\n",
    "sns.barplot(vc.index, vc.values)\n",
    "plt.show()\n",
    "sub.to_csv('emsemble%.5f.csv' % score, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
