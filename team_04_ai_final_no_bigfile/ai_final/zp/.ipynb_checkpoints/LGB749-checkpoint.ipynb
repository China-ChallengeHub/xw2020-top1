{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', 600)\n",
    "pd.set_option('display.max_rows', 600)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "def q10(x):\n",
    "    return x.quantile(0.1)\n",
    "\n",
    "\n",
    "def q20(x):\n",
    "    return x.quantile(0.2)\n",
    "\n",
    "\n",
    "def q25(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "\n",
    "def q30(x):\n",
    "    return x.quantile(0.3)\n",
    "\n",
    "\n",
    "def q40(x):\n",
    "    return x.quantile(0.4)\n",
    "\n",
    "\n",
    "def q60(x):\n",
    "    return x.quantile(0.6)\n",
    "\n",
    "\n",
    "def q70(x):\n",
    "    return x.quantile(0.7)\n",
    "\n",
    "\n",
    "def q75(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "\n",
    "def q80(x):\n",
    "    return x.quantile(0.8)\n",
    "\n",
    "\n",
    "def q90(x):\n",
    "    return x.quantile(0.9)\n",
    "\n",
    "def feature_test_with_cv(X, y, params=None, cate_feas='auto', nfold=3):\n",
    "    \"\"\"\n",
    "    [For LightGBM ONLY]\n",
    "    Use cross validation to test if the feature distribution is the same in both train and test sets.\n",
    "    y: 'istest' column with valus of 0-1\n",
    "    Example:\n",
    "        df_fea_auc = get_feature_report(df, features=gcn_feas, all_cate_feas=[], params=None,nfold=3)\n",
    "    \"\"\"\n",
    "    if params is None:\n",
    "        params = {\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.1,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'early_stopping_rounds': 25,\n",
    "            'metric': 'auc',\n",
    "            'n_jobs': -1,\n",
    "            'num_leaves': 31,\n",
    "            'seed': 2020\n",
    "        }\n",
    "    sfold = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=2020)\n",
    "    models = []\n",
    "    val_auc = 0\n",
    "    train_auc = 0\n",
    "    oof = np.zeros(len(X))\n",
    "    for _, (train_idx, val_idx) in enumerate(sfold.split(X, y)):\n",
    "        train_set = lgb.Dataset(X.iloc[train_idx],\n",
    "                                y.iloc[train_idx],\n",
    "                                categorical_feature=cate_feas)\n",
    "        val_set = lgb.Dataset(X.iloc[val_idx],\n",
    "                              y.iloc[val_idx],\n",
    "                              categorical_feature=cate_feas)\n",
    "        model = lgb.train(params,\n",
    "                          train_set,\n",
    "                          valid_sets=[train_set, val_set],\n",
    "                          verbose_eval=20)\n",
    "        val_auc += model.best_score['valid_1']['auc'] / 3\n",
    "        train_auc += model.best_score['training']['auc'] / 3\n",
    "        oof[val_idx] = model.predict(X.iloc[val_idx])\n",
    "        models.append(model)\n",
    "    return train_auc, val_auc, models, oof\n",
    "\n",
    "def get_feature_report_by_covariate_shift_test(df_raw,\n",
    "                                               features=None,\n",
    "                                               all_cate_feas=[],\n",
    "                                               params=None,\n",
    "                                               nfold=3,\n",
    "                                               y2test='istrain',\n",
    "                                               train_all_feas=False):\n",
    "    \"\"\"\n",
    "    Use cross validation to test if the feature distribution is the same in both train and test sets.\n",
    "    Args:\n",
    "        y2test: target to test, 'istrain' or 'istest'\n",
    "        train_all_feas: if True, the model will be trained with all features together\n",
    "    Return:\n",
    "        result_dict: dict\n",
    "    \"\"\"\n",
    "    df = df_raw.copy()\n",
    "    del df_raw\n",
    "    gc.collect()\n",
    "    if features is None:\n",
    "#         logger.info(\n",
    "#             \"features is none, all cols will be used except 'istrain' or 'istest'!\"\n",
    "#         )\n",
    "        features = [\n",
    "            col for col in df.columns if col not in ['istrain', 'istest']\n",
    "        ]\n",
    "    if train_all_feas:\n",
    "        train_auc, val_auc, models, oof = feature_test_with_cv(\n",
    "            X=df[features],\n",
    "            y=df[y2test],\n",
    "            params=params,\n",
    "            cate_feas=[col for col in all_cate_feas if col in features],\n",
    "            nfold=nfold)\n",
    "        df['pred'] = oof\n",
    "        if y2test == 'istrain':\n",
    "            weights = df[df['istrain'] == 1]['pred'].values\n",
    "            weights = (1. / weights) - 1.\n",
    "            weights /= np.mean(weights)\n",
    "        elif y2test == 'istest':\n",
    "            weights = df[df['istest'] == 0]['pred'].values\n",
    "            weights = (1. / (1 - weights)) - 1.\n",
    "            weights /= np.mean(weights)\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                \"y2test should be in ['istrain','istest'] !\")\n",
    "        result_dict = {\n",
    "            'train_auc': train_auc,\n",
    "            'val_auc': val_auc,\n",
    "            'models': models,\n",
    "            'weights': weights\n",
    "        }\n",
    "    else:\n",
    "        score_lst = []\n",
    "        fea_lst = []\n",
    "        for fea in features:\n",
    "            if fea in all_cate_feas:\n",
    "                cate_feas = [fea]\n",
    "            else:\n",
    "                cate_feas = 'auto'\n",
    "#             logger.info(\"=\" * 30)\n",
    "#             logger.info(f\"Testing: <{fea}> ...\")\n",
    "#             logger.info(\"=\" * 30)\n",
    "            train_auc, val_auc, _, _ = feature_test_with_cv(\n",
    "                X=df[[fea]],\n",
    "                y=df[y2test],\n",
    "                params=params,\n",
    "                cate_feas=cate_feas,\n",
    "                nfold=nfold)\n",
    "            fea_lst.append(fea)\n",
    "            score_lst.append((train_auc, val_auc))\n",
    "        df_fea_auc = pd.DataFrame(score_lst, columns=['train_auc', 'val_auc'])\n",
    "        df_fea_auc['feat'] = fea_lst\n",
    "        df_fea_auc = df_fea_auc.sort_values(by='val_auc', ascending=False)\n",
    "        result_dict = {'df_fea_auc': df_fea_auc}\n",
    "    return result_dict\n",
    "\n",
    "def train_lgb(used_feat_,train_x,train_y,test_x,seed_num=3):\n",
    "    scores = []\n",
    "    imp = pd.DataFrame()\n",
    "    imp['feat'] = used_feat_\n",
    "    print(len(used_feat_),\" : \",used_feat_)\n",
    "    train_x = train_x[used_feat_]\n",
    "    test_x = test_x[used_feat_]\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': 0.1,\n",
    "        'metric': 'multi_error',\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 19,\n",
    "        'feature_fraction': 0.80,\n",
    "        'bagging_fraction': 0.75,\n",
    "        'bagging_freq': 2,\n",
    "        'n_jobs': 4,\n",
    "        'seed': 2020,\n",
    "        'max_depth': 10,\n",
    "        'num_leaves': 64,\n",
    "        'lambda_l1': 0.5,\n",
    "        'lambda_l2': 0.5,\n",
    "    }\n",
    "\n",
    "    oof_train = np.zeros((len(train_x), pd.Series(train_y).nunique()))\n",
    "    preds = np.zeros((len(test_x), pd.Series(train_y).nunique()))\n",
    "    folds = 5\n",
    "    seeds = [44, 2020, 527, 1527]\n",
    "    for seed in seeds[:seed_num]:\n",
    "        print(\"seed:\",seed)\n",
    "        kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "        for fold, (trn_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "            print(\"seed:\",seed,\"fold:\",fold)\n",
    "            x_trn, y_trn, x_val, y_val = train_x.iloc[trn_idx], train_y.iloc[trn_idx], train_x.iloc[val_idx], train_y.iloc[val_idx]\n",
    "            \n",
    "            train_set = lgb.Dataset(x_trn, y_trn)\n",
    "            val_set = lgb.Dataset(x_val, y_val)\n",
    "            model = lgb.train(params, train_set, num_boost_round=5000,\n",
    "                              valid_sets=(train_set,val_set), early_stopping_rounds=50,\n",
    "                              verbose_eval=100)\n",
    "            oof_train[val_idx] += model.predict(x_val) / seed_num\n",
    "            preds += model.predict(test_x) / folds / seed_num\n",
    "           \n",
    "#             print(model.best_score)\n",
    "            scores.append(model.best_score['valid_1']['multi_error'])\n",
    "            imp['gain' + str(fold + 1)] = model.feature_importance(importance_type='gain')\n",
    "            imp['split' + str(fold + 1)] = model.feature_importance(importance_type='split')\n",
    "            \n",
    "            \n",
    "            del x_trn, y_trn, x_val, y_val, model, train_set, val_set\n",
    "            gc.collect()\n",
    "    imp['gain'] = imp[[f for f in imp.columns if 'gain' in f]].sum(axis=1)/folds\n",
    "    imp['split'] = imp[[f for f in imp.columns if 'split' in f]].sum(axis=1)\n",
    "    imp = imp.sort_values(by=['gain'], ascending=False)\n",
    "    imp[['feat', 'gain', 'split']]\n",
    "    imp = imp.sort_values(by=['split'], ascending=False)\n",
    "    print(imp[['feat', 'gain', 'split']])\n",
    "    print(\"--------------------finished-------------------\")\n",
    "    return oof_train,preds\n",
    "\n",
    "    \n",
    "from scipy.stats import entropy    \n",
    "def entropy_values(x):\n",
    "    x = pd.Series(x)\n",
    "    return entropy(x.value_counts() / x.shape[0])\n",
    "    \n",
    "\n",
    "def kurt(x):\n",
    "    return pd.Series(x).kurt()\n",
    "\n",
    "\n",
    "def mode(x):\n",
    "    '''\n",
    "    return the mode of x, if the mode is not unique, return the first one in the sequence.\n",
    "    sample：\n",
    "        a = [1,1,2,2,3]# 1\n",
    "        b = [1,2,2,3]  # 2\n",
    "        mode(a)\n",
    "        mode(b)\n",
    "\n",
    "    '''\n",
    "    return pd.Series(x).mode()[0]\n",
    "\n",
    "\n",
    "from scipy.stats import moment\n",
    "def fourth_moment(x):\n",
    "    '''sample:\n",
    "        fourth_moment([1,2,3])#2.3907061857313376\n",
    "    '''\n",
    "    return moment(x,4)\n",
    "\n",
    "\n",
    "def fifth_moment(x):\n",
    "    '''sample:\n",
    "        fifth_moment([1,2,3])#2.4703447490385586\n",
    "    '''\n",
    "    return moment(x,5)\n",
    "\n",
    "\n",
    "def range_value(x):\n",
    "    '''\n",
    "    range(极差) of x,\n",
    "    '''\n",
    "    return x.max() - x.min()\n",
    "\n",
    "\n",
    "def root_mean_square(x):\n",
    "    '''\n",
    "    root_mean_square\n",
    "    sample:\n",
    "        root_mean_square([1,2,3])#2.160246899469287\n",
    "    '''\n",
    "    return np.sqrt(np.mean(np.array(x) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.888888888888889"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 * 400 * 5 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow_addons.optimizers import AdamW\n",
    "# import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path  = '../data/final_data/'\n",
    "data_train = pd.read_csv(root_path+'sensor_train_final.csv')\n",
    "data_test = pd.read_csv(root_path+'sensor_test_final.csv')\n",
    "sub = pd.read_csv(root_path+'submit_example.csv')\n",
    "y = data_train.groupby('fragment_id')['behavior_id'].min()\n",
    "data_test['fragment_id'] += 100000\n",
    "label = 'behavior_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fragment_id</th>\n",
       "      <th>time_point</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>acc_xg</th>\n",
       "      <th>acc_yg</th>\n",
       "      <th>acc_zg</th>\n",
       "      <th>behavior_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>1.31</td>\n",
       "      <td>9.51</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>1.31</td>\n",
       "      <td>9.51</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1.29</td>\n",
       "      <td>9.58</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>1.32</td>\n",
       "      <td>9.52</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>1.29</td>\n",
       "      <td>9.58</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fragment_id  time_point  acc_x  acc_y  acc_z  acc_xg  acc_yg  acc_zg  \\\n",
       "0            0          37   -0.1    0.0   -0.1   -0.49    1.31    9.51   \n",
       "1            0         123    0.0    0.0   -0.1   -0.49    1.31    9.51   \n",
       "2            0         210    0.0   -0.0    0.1   -0.41    1.29    9.58   \n",
       "3            0         291    0.0    0.0    0.0   -0.38    1.32    9.52   \n",
       "4            0         375    0.1    0.0    0.1   -0.31    1.29    9.58   \n",
       "\n",
       "   behavior_id  \n",
       "0           11  \n",
       "1           11  \n",
       "2           11  \n",
       "3           11  \n",
       "4           11  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:30<00:00,  3.35s/it]\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([data_train, data_test], sort=False,ignore_index=True)\n",
    "df = data.drop_duplicates(subset=['fragment_id']).reset_index(drop=True)[['fragment_id', 'behavior_id']]\n",
    "\n",
    "data['acc'] = (data['acc_x'] ** 2 + data['acc_y'] ** 2 + data['acc_z'] ** 2) ** 0.5\n",
    "data['accg'] = (data['acc_xg'] ** 2 + data['acc_yg'] ** 2 + data['acc_zg'] ** 2) ** 0.5\n",
    "\n",
    "data = data.sort_values(['fragment_id','time_point'],ascending=False)\n",
    "# data = data.set_index(['fragment_id','time_point'])\n",
    "data['acc_time_diff'] = data.groupby([\"fragment_id\"])[\"time_point\"].diff(1)\n",
    "# data = data.reset_index()\n",
    "for fdata in tqdm([f for f in data.columns if 'acc' in f]):\n",
    "    for stat in ['min', 'max', 'mean', 'median', 'std', 'skew']:\n",
    "        df[fdata+'_'+stat] = data.groupby('fragment_id')[fdata].agg(stat).values\n",
    "\n",
    "# df[\"time_count\"] = df.merge(d/\"ata.groupby(\"fragment_id\")[\"acc\"].count(),on='fragment_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        -86.0\n",
       "0        -85.0\n",
       "1        -87.0\n",
       "1        -83.0\n",
       "2        -81.0\n",
       "          ... \n",
       "420416   -82.0\n",
       "420417   -85.0\n",
       "420418   -82.0\n",
       "420419   -84.0\n",
       "420420     NaN\n",
       "Name: time_point, Length: 812215, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data.groupby([\"fragment_id\"])[\"time_point\"].diff(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fragment_id\n",
       "0         20\n",
       "1         22\n",
       "2         39\n",
       "3         28\n",
       "4         10\n",
       "          ..\n",
       "115995    42\n",
       "115996    52\n",
       "115997    33\n",
       "115998    12\n",
       "115999    28\n",
       "Name: acc, Length: 31000, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"fragment_id\")[\"acc\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "['acc_x_min', 'acc_x_max', 'acc_x_mean', 'acc_x_median', 'acc_x_std', 'acc_x_skew', 'acc_y_min', 'acc_y_max', 'acc_y_mean', 'acc_y_median', 'acc_y_std', 'acc_y_skew', 'acc_z_min', 'acc_z_max', 'acc_z_mean', 'acc_z_median', 'acc_z_std', 'acc_z_skew', 'acc_xg_min', 'acc_xg_max', 'acc_xg_mean', 'acc_xg_median', 'acc_xg_std', 'acc_xg_skew', 'acc_yg_min', 'acc_yg_max', 'acc_yg_mean', 'acc_yg_median', 'acc_yg_std', 'acc_yg_skew', 'acc_zg_min', 'acc_zg_max', 'acc_zg_mean', 'acc_zg_median', 'acc_zg_std', 'acc_zg_skew', 'acc_min', 'acc_max', 'acc_mean', 'acc_median', 'acc_std', 'acc_skew', 'accg_min', 'accg_max', 'accg_mean', 'accg_median', 'accg_std', 'accg_skew', 'acc_time_diff_min', 'acc_time_diff_max', 'acc_time_diff_mean', 'acc_time_diff_median', 'acc_time_diff_std', 'acc_time_diff_skew']\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df[label].isna()==False].reset_index(drop=True)\n",
    "test_df = df[df[label].isna()==True].reset_index(drop=True)\n",
    "\n",
    "drop_feat = []\n",
    "used_feat = [f for f in train_df.columns if f not in (['fragment_id', label] + drop_feat)]\n",
    "print(len(used_feat))\n",
    "print(used_feat)\n",
    "\n",
    "train_x = train_df[used_feat]\n",
    "train_y = train_df[label]\n",
    "test_x = test_df[used_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "['acc_x_min', 'acc_x_max', 'acc_x_mean', 'acc_x_median', 'acc_x_std', 'acc_x_skew', 'acc_y_min', 'acc_y_max', 'acc_y_mean', 'acc_y_median', 'acc_y_std', 'acc_y_skew', 'acc_z_min', 'acc_z_max', 'acc_z_mean', 'acc_z_median', 'acc_z_std', 'acc_z_skew', 'acc_xg_min', 'acc_xg_max', 'acc_xg_mean', 'acc_xg_median', 'acc_xg_std', 'acc_xg_skew', 'acc_yg_min', 'acc_yg_max', 'acc_yg_mean', 'acc_yg_median', 'acc_yg_std', 'acc_yg_skew', 'acc_zg_min', 'acc_zg_max', 'acc_zg_mean', 'acc_zg_median', 'acc_zg_std', 'acc_zg_skew', 'acc_min', 'acc_max', 'acc_mean', 'acc_median', 'acc_std', 'acc_skew', 'accg_min', 'accg_max', 'accg_mean', 'accg_median', 'accg_std', 'accg_skew', 'acc_time_diff_min', 'acc_time_diff_max', 'acc_time_diff_mean', 'acc_time_diff_median', 'acc_time_diff_std', 'acc_time_diff_skew']\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df[label].isna()==False].reset_index(drop=True)\n",
    "test_df = df[df[label].isna()==True].reset_index(drop=True)\n",
    "\n",
    "drop_feat = []\n",
    "used_feat = [f for f in train_df.columns if f not in (['fragment_id', label] + drop_feat)]\n",
    "print(len(used_feat))\n",
    "print(used_feat)\n",
    "\n",
    "train_x = train_df[used_feat]\n",
    "train_y = train_df[label]\n",
    "test_x = test_df[used_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0851667\tvalid_1's multi_error: 0.239\n",
      "[40]\ttraining's multi_error: 0.0323333\tvalid_1's multi_error: 0.218333\n",
      "[60]\ttraining's multi_error: 0.00741667\tvalid_1's multi_error: 0.207\n",
      "[80]\ttraining's multi_error: 0.00225\tvalid_1's multi_error: 0.199333\n",
      "[100]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.193\n",
      "[120]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.189\n",
      "[140]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.190667\n",
      "[160]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.190333\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0815833\tvalid_1's multi_error: 0.255333\n",
      "[40]\ttraining's multi_error: 0.02975\tvalid_1's multi_error: 0.225333\n",
      "[60]\ttraining's multi_error: 0.00733333\tvalid_1's multi_error: 0.210667\n",
      "[80]\ttraining's multi_error: 0.00141667\tvalid_1's multi_error: 0.208\n",
      "[100]\ttraining's multi_error: 0.0005\tvalid_1's multi_error: 0.204\n",
      "[120]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.196333\n",
      "[140]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.194333\n",
      "[160]\ttraining's multi_error: 0.00025\tvalid_1's multi_error: 0.194333\n",
      "[180]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.192667\n",
      "[200]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.193\n",
      "[220]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.194333\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.190333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0810833\tvalid_1's multi_error: 0.246\n",
      "[40]\ttraining's multi_error: 0.0281667\tvalid_1's multi_error: 0.223333\n",
      "[60]\ttraining's multi_error: 0.00725\tvalid_1's multi_error: 0.210667\n",
      "[80]\ttraining's multi_error: 0.00116667\tvalid_1's multi_error: 0.201\n",
      "[100]\ttraining's multi_error: 0.000833333\tvalid_1's multi_error: 0.2\n",
      "[120]\ttraining's multi_error: 0.0005\tvalid_1's multi_error: 0.196\n",
      "[140]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.194\n",
      "[160]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.193\n",
      "[180]\ttraining's multi_error: 0.00025\tvalid_1's multi_error: 0.193667\n",
      "[200]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.192667\n",
      "[220]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.192667\n",
      "[240]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.192667\n",
      "Early stopping, best iteration is:\n",
      "[209]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.191667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.07975\tvalid_1's multi_error: 0.257\n",
      "[40]\ttraining's multi_error: 0.02775\tvalid_1's multi_error: 0.229667\n",
      "[60]\ttraining's multi_error: 0.00641667\tvalid_1's multi_error: 0.221\n",
      "[80]\ttraining's multi_error: 0.00183333\tvalid_1's multi_error: 0.220667\n",
      "[100]\ttraining's multi_error: 0.000916667\tvalid_1's multi_error: 0.216333\n",
      "[120]\ttraining's multi_error: 0.000583333\tvalid_1's multi_error: 0.212333\n",
      "[140]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.210333\n",
      "[160]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.210667\n",
      "[180]\ttraining's multi_error: 0.00025\tvalid_1's multi_error: 0.210667\n",
      "[200]\ttraining's multi_error: 0.00025\tvalid_1's multi_error: 0.208\n",
      "[220]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.208667\n",
      "[240]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.207667\n",
      "Early stopping, best iteration is:\n",
      "[201]\ttraining's multi_error: 0.00025\tvalid_1's multi_error: 0.207333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "648"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0839167\tvalid_1's multi_error: 0.259333\n",
      "[40]\ttraining's multi_error: 0.0293333\tvalid_1's multi_error: 0.233667\n",
      "[60]\ttraining's multi_error: 0.00625\tvalid_1's multi_error: 0.218\n",
      "[80]\ttraining's multi_error: 0.00125\tvalid_1's multi_error: 0.212667\n",
      "[100]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.209667\n",
      "[120]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.206\n",
      "[140]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.207\n",
      "[160]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.206667\n",
      "Early stopping, best iteration is:\n",
      "[122]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.205333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0829167\tvalid_1's multi_error: 0.258\n",
      "[40]\ttraining's multi_error: 0.02975\tvalid_1's multi_error: 0.232333\n",
      "[60]\ttraining's multi_error: 0.00766667\tvalid_1's multi_error: 0.220667\n",
      "[80]\ttraining's multi_error: 0.00158333\tvalid_1's multi_error: 0.213\n",
      "[100]\ttraining's multi_error: 0.0005\tvalid_1's multi_error: 0.211\n",
      "[120]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.208667\n",
      "[140]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.204\n",
      "[160]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.205667\n",
      "[180]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.207333\n",
      "Early stopping, best iteration is:\n",
      "[138]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.203667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0828333\tvalid_1's multi_error: 0.25\n",
      "[40]\ttraining's multi_error: 0.0291667\tvalid_1's multi_error: 0.224\n",
      "[60]\ttraining's multi_error: 0.008\tvalid_1's multi_error: 0.210333\n",
      "[80]\ttraining's multi_error: 0.00241667\tvalid_1's multi_error: 0.206667\n",
      "[100]\ttraining's multi_error: 0.000916667\tvalid_1's multi_error: 0.202333\n",
      "[120]\ttraining's multi_error: 0.000666667\tvalid_1's multi_error: 0.201333\n",
      "[140]\ttraining's multi_error: 0.0005\tvalid_1's multi_error: 0.198333\n",
      "[160]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.197333\n",
      "[180]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.197\n",
      "[200]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.195333\n",
      "[220]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.194\n",
      "[240]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.194333\n",
      "Early stopping, best iteration is:\n",
      "[207]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.08075\tvalid_1's multi_error: 0.257667\n",
      "[40]\ttraining's multi_error: 0.029\tvalid_1's multi_error: 0.234\n",
      "[60]\ttraining's multi_error: 0.00808333\tvalid_1's multi_error: 0.223667\n",
      "[80]\ttraining's multi_error: 0.002\tvalid_1's multi_error: 0.214667\n",
      "[100]\ttraining's multi_error: 0.000583333\tvalid_1's multi_error: 0.209333\n",
      "[120]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.206667\n",
      "[140]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.202667\n",
      "[160]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.2\n",
      "[180]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.199\n",
      "[200]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.200333\n",
      "[220]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.200333\n",
      "[240]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.202\n",
      "Early stopping, best iteration is:\n",
      "[194]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.198333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "620"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.086\tvalid_1's multi_error: 0.242333\n",
      "[40]\ttraining's multi_error: 0.0305\tvalid_1's multi_error: 0.213\n",
      "[60]\ttraining's multi_error: 0.009\tvalid_1's multi_error: 0.205333\n",
      "[80]\ttraining's multi_error: 0.00208333\tvalid_1's multi_error: 0.197333\n",
      "[100]\ttraining's multi_error: 0.000666667\tvalid_1's multi_error: 0.195667\n",
      "[120]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.19\n",
      "[140]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.193333\n",
      "[160]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.191667\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0819167\tvalid_1's multi_error: 0.251667\n",
      "[40]\ttraining's multi_error: 0.0280833\tvalid_1's multi_error: 0.225667\n",
      "[60]\ttraining's multi_error: 0.00766667\tvalid_1's multi_error: 0.211333\n",
      "[80]\ttraining's multi_error: 0.00166667\tvalid_1's multi_error: 0.208333\n",
      "[100]\ttraining's multi_error: 0.000666667\tvalid_1's multi_error: 0.205667\n",
      "[120]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.200333\n",
      "[140]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.200333\n",
      "[160]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.202333\n",
      "[180]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.198667\n",
      "[200]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.198333\n",
      "[220]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.197667\n",
      "[240]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.197333\n",
      "[260]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.198333\n",
      "[280]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.197\n",
      "[300]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.196667\n",
      "[320]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.197333\n",
      "Early stopping, best iteration is:\n",
      "[283]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.196333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0841667\tvalid_1's multi_error: 0.245667\n",
      "[40]\ttraining's multi_error: 0.03075\tvalid_1's multi_error: 0.223\n",
      "[60]\ttraining's multi_error: 0.00708333\tvalid_1's multi_error: 0.209333\n",
      "[80]\ttraining's multi_error: 0.00158333\tvalid_1's multi_error: 0.204667\n",
      "[100]\ttraining's multi_error: 0.000833333\tvalid_1's multi_error: 0.197333\n",
      "[120]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.195667\n",
      "[140]\ttraining's multi_error: 0.00025\tvalid_1's multi_error: 0.195667\n",
      "[160]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.192667\n",
      "[180]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.191667\n",
      "[200]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.193667\n",
      "[220]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.194333\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.191667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.081\tvalid_1's multi_error: 0.245333\n",
      "[40]\ttraining's multi_error: 0.0301667\tvalid_1's multi_error: 0.220667\n",
      "[60]\ttraining's multi_error: 0.00866667\tvalid_1's multi_error: 0.213\n",
      "[80]\ttraining's multi_error: 0.00166667\tvalid_1's multi_error: 0.209667\n",
      "[100]\ttraining's multi_error: 0.00075\tvalid_1's multi_error: 0.204667\n",
      "[120]\ttraining's multi_error: 0.0005\tvalid_1's multi_error: 0.204667\n",
      "[140]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.203667\n",
      "[160]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.206333\n",
      "[180]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.204\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.202667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0855833\tvalid_1's multi_error: 0.263667\n",
      "[40]\ttraining's multi_error: 0.03075\tvalid_1's multi_error: 0.238667\n",
      "[60]\ttraining's multi_error: 0.00791667\tvalid_1's multi_error: 0.226333\n",
      "[80]\ttraining's multi_error: 0.00191667\tvalid_1's multi_error: 0.224333\n",
      "[100]\ttraining's multi_error: 0.00116667\tvalid_1's multi_error: 0.219\n",
      "[120]\ttraining's multi_error: 0.000583333\tvalid_1's multi_error: 0.217667\n",
      "[140]\ttraining's multi_error: 0.000583333\tvalid_1's multi_error: 0.215333\n",
      "[160]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.213667\n",
      "[180]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.211667\n",
      "[200]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.208667\n",
      "[220]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.21\n",
      "[240]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.210333\n",
      "Early stopping, best iteration is:\n",
      "[201]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.208333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "648"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0838333\tvalid_1's multi_error: 0.258667\n",
      "[40]\ttraining's multi_error: 0.0295\tvalid_1's multi_error: 0.228667\n",
      "[60]\ttraining's multi_error: 0.00858333\tvalid_1's multi_error: 0.214333\n",
      "[80]\ttraining's multi_error: 0.0015\tvalid_1's multi_error: 0.208333\n",
      "[100]\ttraining's multi_error: 0.00075\tvalid_1's multi_error: 0.204333\n",
      "[120]\ttraining's multi_error: 0.0005\tvalid_1's multi_error: 0.201\n",
      "[140]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.201667\n",
      "[160]\ttraining's multi_error: 0.00025\tvalid_1's multi_error: 0.199\n",
      "[180]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.198333\n",
      "[200]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.197\n",
      "[220]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.197667\n",
      "[240]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.198667\n",
      "Early stopping, best iteration is:\n",
      "[199]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0804167\tvalid_1's multi_error: 0.255333\n",
      "[40]\ttraining's multi_error: 0.0291667\tvalid_1's multi_error: 0.232667\n",
      "[60]\ttraining's multi_error: 0.00783333\tvalid_1's multi_error: 0.221333\n",
      "[80]\ttraining's multi_error: 0.00216667\tvalid_1's multi_error: 0.217667\n",
      "[100]\ttraining's multi_error: 0.001\tvalid_1's multi_error: 0.212333\n",
      "[120]\ttraining's multi_error: 0.000666667\tvalid_1's multi_error: 0.211333\n",
      "[140]\ttraining's multi_error: 0.000583333\tvalid_1's multi_error: 0.209667\n",
      "[160]\ttraining's multi_error: 0.0005\tvalid_1's multi_error: 0.209\n",
      "[180]\ttraining's multi_error: 0.0005\tvalid_1's multi_error: 0.208667\n",
      "[200]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.208667\n",
      "[220]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.207\n",
      "[240]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.208667\n",
      "[260]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.209333\n",
      "Early stopping, best iteration is:\n",
      "[228]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.206333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0809167\tvalid_1's multi_error: 0.249667\n",
      "[40]\ttraining's multi_error: 0.03075\tvalid_1's multi_error: 0.227667\n",
      "[60]\ttraining's multi_error: 0.00816667\tvalid_1's multi_error: 0.211667\n",
      "[80]\ttraining's multi_error: 0.00241667\tvalid_1's multi_error: 0.206667\n",
      "[100]\ttraining's multi_error: 0.000666667\tvalid_1's multi_error: 0.203333\n",
      "[120]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.201333\n",
      "[140]\ttraining's multi_error: 0.00025\tvalid_1's multi_error: 0.198667\n",
      "[160]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.2\n",
      "[180]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.199333\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttraining's multi_error: 0.00025\tvalid_1's multi_error: 0.197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0831667\tvalid_1's multi_error: 0.249667\n",
      "[40]\ttraining's multi_error: 0.029\tvalid_1's multi_error: 0.225667\n",
      "[60]\ttraining's multi_error: 0.00683333\tvalid_1's multi_error: 0.210667\n",
      "[80]\ttraining's multi_error: 0.00158333\tvalid_1's multi_error: 0.207\n",
      "[100]\ttraining's multi_error: 0.0005\tvalid_1's multi_error: 0.205\n",
      "[120]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.203667\n",
      "[140]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.202333\n",
      "[160]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.203333\n",
      "[180]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.199667\n",
      "[200]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.201\n",
      "[220]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.2\n",
      "[240]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.199\n",
      "[260]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.199\n",
      "[280]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.199667\n",
      "Early stopping, best iteration is:\n",
      "[245]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0829167\tvalid_1's multi_error: 0.257\n",
      "[40]\ttraining's multi_error: 0.0309167\tvalid_1's multi_error: 0.23\n",
      "[60]\ttraining's multi_error: 0.008\tvalid_1's multi_error: 0.217\n",
      "[80]\ttraining's multi_error: 0.00183333\tvalid_1's multi_error: 0.213\n",
      "[100]\ttraining's multi_error: 0.000583333\tvalid_1's multi_error: 0.208333\n",
      "[120]\ttraining's multi_error: 0.00025\tvalid_1's multi_error: 0.205667\n",
      "[140]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.206333\n",
      "[160]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.204\n",
      "[180]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.203667\n",
      "[200]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.203333\n",
      "[220]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.202667\n",
      "[240]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.199333\n",
      "[260]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.200333\n",
      "[280]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.201333\n",
      "Early stopping, best iteration is:\n",
      "[245]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.198667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0895833\tvalid_1's multi_error: 0.251333\n",
      "[40]\ttraining's multi_error: 0.0315\tvalid_1's multi_error: 0.225333\n",
      "[60]\ttraining's multi_error: 0.00825\tvalid_1's multi_error: 0.216333\n",
      "[80]\ttraining's multi_error: 0.00208333\tvalid_1's multi_error: 0.21\n",
      "[100]\ttraining's multi_error: 0.000833333\tvalid_1's multi_error: 0.205\n",
      "[120]\ttraining's multi_error: 0.0005\tvalid_1's multi_error: 0.206\n",
      "[140]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.203333\n",
      "[160]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.202667\n",
      "[180]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.203333\n",
      "[200]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.201667\n",
      "[220]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.199333\n",
      "[240]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.198333\n",
      "[260]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.198\n",
      "[280]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.198667\n",
      "[300]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.199\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.197333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0839167\tvalid_1's multi_error: 0.258667\n",
      "[40]\ttraining's multi_error: 0.02825\tvalid_1's multi_error: 0.234667\n",
      "[60]\ttraining's multi_error: 0.00758333\tvalid_1's multi_error: 0.219667\n",
      "[80]\ttraining's multi_error: 0.00133333\tvalid_1's multi_error: 0.216\n",
      "[100]\ttraining's multi_error: 0.0005\tvalid_1's multi_error: 0.216\n",
      "[120]\ttraining's multi_error: 0.00025\tvalid_1's multi_error: 0.212333\n",
      "[140]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.209667\n",
      "[160]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.209333\n",
      "[180]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.209667\n",
      "[200]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.210333\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.207333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "imp = pd.DataFrame()\n",
    "imp['feat'] = used_feat\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'metric': 'multi_error',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 20,\n",
    "    'feature_fraction': 0.80,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 2,\n",
    "    'n_jobs': 4,\n",
    "    'seed': 2020,\n",
    "    'max_depth': 10,\n",
    "    'num_leaves': 64,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 0.5,\n",
    "}\n",
    "\n",
    "oof_train = np.zeros((len(train_x), 20))\n",
    "preds = np.zeros((len(test_x), 20))\n",
    "folds = 5\n",
    "seeds = [44, 2020, 527, 1527]\n",
    "for seed in seeds:\n",
    "    kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        x_trn, y_trn, x_val, y_val = train_x.iloc[trn_idx], train_y.iloc[trn_idx], train_x.iloc[val_idx], train_y.iloc[val_idx]\n",
    "        train_set = lgb.Dataset(x_trn, y_trn)\n",
    "        val_set = lgb.Dataset(x_val, y_val)\n",
    "\n",
    "        model = lgb.train(params, train_set, num_boost_round=500000,\n",
    "                          valid_sets=(train_set, val_set), early_stopping_rounds=50,\n",
    "                          verbose_eval=20)\n",
    "        oof_train[val_idx] += model.predict(x_val) / len(seeds)\n",
    "        preds += model.predict(test_x) / folds / len(seeds)\n",
    "        scores.append(model.best_score['valid_1']['multi_error'])\n",
    "        imp['gain' + str(fold + 1)] = model.feature_importance(importance_type='gain')\n",
    "        imp['split' + str(fold + 1)] = model.feature_importance(importance_type='split')\n",
    "        del x_trn, y_trn, x_val, y_val, model, train_set, val_set\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>acc_yg_max</td>\n",
       "      <td>25294.949096</td>\n",
       "      <td>43494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>acc_zg_std</td>\n",
       "      <td>21500.983991</td>\n",
       "      <td>22182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>acc_zg_min</td>\n",
       "      <td>20565.018749</td>\n",
       "      <td>40450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>acc_yg_min</td>\n",
       "      <td>18269.388275</td>\n",
       "      <td>46142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>acc_xg_max</td>\n",
       "      <td>12991.348483</td>\n",
       "      <td>49244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>acc_xg_min</td>\n",
       "      <td>12235.218745</td>\n",
       "      <td>46896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>acc_zg_mean</td>\n",
       "      <td>11904.538372</td>\n",
       "      <td>40356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>acc_yg_mean</td>\n",
       "      <td>11198.818746</td>\n",
       "      <td>36524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>accg_mean</td>\n",
       "      <td>10343.408568</td>\n",
       "      <td>55282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>acc_xg_mean</td>\n",
       "      <td>10029.531011</td>\n",
       "      <td>43220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>acc_median</td>\n",
       "      <td>9867.624252</td>\n",
       "      <td>24508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acc_x_std</td>\n",
       "      <td>9501.445653</td>\n",
       "      <td>26746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>acc_yg_median</td>\n",
       "      <td>9494.822946</td>\n",
       "      <td>32826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>acc_time_diff_mean</td>\n",
       "      <td>9295.477116</td>\n",
       "      <td>61650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>acc_time_diff_std</td>\n",
       "      <td>9191.420281</td>\n",
       "      <td>55302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>acc_min</td>\n",
       "      <td>8333.772215</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>acc_zg_max</td>\n",
       "      <td>8286.295207</td>\n",
       "      <td>31240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>acc_y_std</td>\n",
       "      <td>8220.647170</td>\n",
       "      <td>32564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>acc_zg_median</td>\n",
       "      <td>7952.690118</td>\n",
       "      <td>35940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acc_y_mean</td>\n",
       "      <td>7475.683666</td>\n",
       "      <td>49096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>acc_xg_median</td>\n",
       "      <td>6733.662942</td>\n",
       "      <td>39244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>acc_xg_std</td>\n",
       "      <td>6195.305458</td>\n",
       "      <td>33450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>acc_time_diff_median</td>\n",
       "      <td>6097.832098</td>\n",
       "      <td>22692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>accg_median</td>\n",
       "      <td>5570.337669</td>\n",
       "      <td>48658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>acc_time_diff_max</td>\n",
       "      <td>5291.183610</td>\n",
       "      <td>30740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>acc_yg_std</td>\n",
       "      <td>4705.164250</td>\n",
       "      <td>36476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>acc_z_mean</td>\n",
       "      <td>4657.786486</td>\n",
       "      <td>41552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>acc_time_diff_skew</td>\n",
       "      <td>4185.690966</td>\n",
       "      <td>47266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>acc_mean</td>\n",
       "      <td>3535.606403</td>\n",
       "      <td>15528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>acc_y_median</td>\n",
       "      <td>3508.421298</td>\n",
       "      <td>27302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acc_x_mean</td>\n",
       "      <td>2935.989707</td>\n",
       "      <td>41928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>acc_time_diff_min</td>\n",
       "      <td>2516.145097</td>\n",
       "      <td>21670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>acc_z_std</td>\n",
       "      <td>2249.194533</td>\n",
       "      <td>19036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acc_y_min</td>\n",
       "      <td>2170.755147</td>\n",
       "      <td>18832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>accg_std</td>\n",
       "      <td>2149.129585</td>\n",
       "      <td>18694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>accg_min</td>\n",
       "      <td>2081.491659</td>\n",
       "      <td>26096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>acc_skew</td>\n",
       "      <td>2048.933993</td>\n",
       "      <td>39436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>acc_yg_skew</td>\n",
       "      <td>1883.434089</td>\n",
       "      <td>40960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>acc_y_skew</td>\n",
       "      <td>1789.968968</td>\n",
       "      <td>39762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>acc_std</td>\n",
       "      <td>1769.210481</td>\n",
       "      <td>18140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>acc_z_median</td>\n",
       "      <td>1743.562625</td>\n",
       "      <td>24588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acc_x_median</td>\n",
       "      <td>1696.419379</td>\n",
       "      <td>25382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acc_x_skew</td>\n",
       "      <td>1649.033498</td>\n",
       "      <td>38522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>acc_xg_skew</td>\n",
       "      <td>1647.632569</td>\n",
       "      <td>39798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acc_y_max</td>\n",
       "      <td>1615.059367</td>\n",
       "      <td>22074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>acc_zg_skew</td>\n",
       "      <td>1545.995932</td>\n",
       "      <td>33856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>acc_z_skew</td>\n",
       "      <td>1523.438171</td>\n",
       "      <td>34938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>acc_z_min</td>\n",
       "      <td>1399.548385</td>\n",
       "      <td>18962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>accg_max</td>\n",
       "      <td>1390.769687</td>\n",
       "      <td>20832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>accg_skew</td>\n",
       "      <td>1374.817968</td>\n",
       "      <td>31488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acc_x_max</td>\n",
       "      <td>1330.204382</td>\n",
       "      <td>19226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc_x_min</td>\n",
       "      <td>1200.697379</td>\n",
       "      <td>19216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>acc_z_max</td>\n",
       "      <td>1098.797518</td>\n",
       "      <td>16238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>acc_max</td>\n",
       "      <td>1020.279545</td>\n",
       "      <td>12724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feat          gain  split\n",
       "25            acc_yg_max  25294.949096  43494\n",
       "34            acc_zg_std  21500.983991  22182\n",
       "30            acc_zg_min  20565.018749  40450\n",
       "24            acc_yg_min  18269.388275  46142\n",
       "19            acc_xg_max  12991.348483  49244\n",
       "18            acc_xg_min  12235.218745  46896\n",
       "32           acc_zg_mean  11904.538372  40356\n",
       "26           acc_yg_mean  11198.818746  36524\n",
       "44             accg_mean  10343.408568  55282\n",
       "20           acc_xg_mean  10029.531011  43220\n",
       "39            acc_median   9867.624252  24508\n",
       "4              acc_x_std   9501.445653  26746\n",
       "27         acc_yg_median   9494.822946  32826\n",
       "50    acc_time_diff_mean   9295.477116  61650\n",
       "52     acc_time_diff_std   9191.420281  55302\n",
       "36               acc_min   8333.772215  32476\n",
       "31            acc_zg_max   8286.295207  31240\n",
       "10             acc_y_std   8220.647170  32564\n",
       "33         acc_zg_median   7952.690118  35940\n",
       "8             acc_y_mean   7475.683666  49096\n",
       "21         acc_xg_median   6733.662942  39244\n",
       "22            acc_xg_std   6195.305458  33450\n",
       "51  acc_time_diff_median   6097.832098  22692\n",
       "45           accg_median   5570.337669  48658\n",
       "49     acc_time_diff_max   5291.183610  30740\n",
       "28            acc_yg_std   4705.164250  36476\n",
       "14            acc_z_mean   4657.786486  41552\n",
       "53    acc_time_diff_skew   4185.690966  47266\n",
       "38              acc_mean   3535.606403  15528\n",
       "9           acc_y_median   3508.421298  27302\n",
       "2             acc_x_mean   2935.989707  41928\n",
       "48     acc_time_diff_min   2516.145097  21670\n",
       "16             acc_z_std   2249.194533  19036\n",
       "6              acc_y_min   2170.755147  18832\n",
       "46              accg_std   2149.129585  18694\n",
       "42              accg_min   2081.491659  26096\n",
       "41              acc_skew   2048.933993  39436\n",
       "29           acc_yg_skew   1883.434089  40960\n",
       "11            acc_y_skew   1789.968968  39762\n",
       "40               acc_std   1769.210481  18140\n",
       "15          acc_z_median   1743.562625  24588\n",
       "3           acc_x_median   1696.419379  25382\n",
       "5             acc_x_skew   1649.033498  38522\n",
       "23           acc_xg_skew   1647.632569  39798\n",
       "7              acc_y_max   1615.059367  22074\n",
       "35           acc_zg_skew   1545.995932  33856\n",
       "17            acc_z_skew   1523.438171  34938\n",
       "12             acc_z_min   1399.548385  18962\n",
       "43              accg_max   1390.769687  20832\n",
       "47             accg_skew   1374.817968  31488\n",
       "1              acc_x_max   1330.204382  19226\n",
       "0              acc_x_min   1200.697379  19216\n",
       "13             acc_z_max   1098.797518  16238\n",
       "37               acc_max   1020.279545  12724"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>acc_time_diff_mean</td>\n",
       "      <td>9295.477116</td>\n",
       "      <td>61650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>acc_time_diff_std</td>\n",
       "      <td>9191.420281</td>\n",
       "      <td>55302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>accg_mean</td>\n",
       "      <td>10343.408568</td>\n",
       "      <td>55282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>acc_xg_max</td>\n",
       "      <td>12991.348483</td>\n",
       "      <td>49244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acc_y_mean</td>\n",
       "      <td>7475.683666</td>\n",
       "      <td>49096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>accg_median</td>\n",
       "      <td>5570.337669</td>\n",
       "      <td>48658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>acc_time_diff_skew</td>\n",
       "      <td>4185.690966</td>\n",
       "      <td>47266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>acc_xg_min</td>\n",
       "      <td>12235.218745</td>\n",
       "      <td>46896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>acc_yg_min</td>\n",
       "      <td>18269.388275</td>\n",
       "      <td>46142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>acc_yg_max</td>\n",
       "      <td>25294.949096</td>\n",
       "      <td>43494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>acc_xg_mean</td>\n",
       "      <td>10029.531011</td>\n",
       "      <td>43220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acc_x_mean</td>\n",
       "      <td>2935.989707</td>\n",
       "      <td>41928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>acc_z_mean</td>\n",
       "      <td>4657.786486</td>\n",
       "      <td>41552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>acc_yg_skew</td>\n",
       "      <td>1883.434089</td>\n",
       "      <td>40960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>acc_zg_min</td>\n",
       "      <td>20565.018749</td>\n",
       "      <td>40450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>acc_zg_mean</td>\n",
       "      <td>11904.538372</td>\n",
       "      <td>40356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>acc_xg_skew</td>\n",
       "      <td>1647.632569</td>\n",
       "      <td>39798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>acc_y_skew</td>\n",
       "      <td>1789.968968</td>\n",
       "      <td>39762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>acc_skew</td>\n",
       "      <td>2048.933993</td>\n",
       "      <td>39436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>acc_xg_median</td>\n",
       "      <td>6733.662942</td>\n",
       "      <td>39244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acc_x_skew</td>\n",
       "      <td>1649.033498</td>\n",
       "      <td>38522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>acc_yg_mean</td>\n",
       "      <td>11198.818746</td>\n",
       "      <td>36524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>acc_yg_std</td>\n",
       "      <td>4705.164250</td>\n",
       "      <td>36476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>acc_zg_median</td>\n",
       "      <td>7952.690118</td>\n",
       "      <td>35940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>acc_z_skew</td>\n",
       "      <td>1523.438171</td>\n",
       "      <td>34938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>acc_zg_skew</td>\n",
       "      <td>1545.995932</td>\n",
       "      <td>33856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>acc_xg_std</td>\n",
       "      <td>6195.305458</td>\n",
       "      <td>33450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>acc_yg_median</td>\n",
       "      <td>9494.822946</td>\n",
       "      <td>32826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>acc_y_std</td>\n",
       "      <td>8220.647170</td>\n",
       "      <td>32564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>acc_min</td>\n",
       "      <td>8333.772215</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>accg_skew</td>\n",
       "      <td>1374.817968</td>\n",
       "      <td>31488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>acc_zg_max</td>\n",
       "      <td>8286.295207</td>\n",
       "      <td>31240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>acc_time_diff_max</td>\n",
       "      <td>5291.183610</td>\n",
       "      <td>30740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>acc_y_median</td>\n",
       "      <td>3508.421298</td>\n",
       "      <td>27302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acc_x_std</td>\n",
       "      <td>9501.445653</td>\n",
       "      <td>26746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>accg_min</td>\n",
       "      <td>2081.491659</td>\n",
       "      <td>26096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acc_x_median</td>\n",
       "      <td>1696.419379</td>\n",
       "      <td>25382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>acc_z_median</td>\n",
       "      <td>1743.562625</td>\n",
       "      <td>24588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>acc_median</td>\n",
       "      <td>9867.624252</td>\n",
       "      <td>24508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>acc_time_diff_median</td>\n",
       "      <td>6097.832098</td>\n",
       "      <td>22692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>acc_zg_std</td>\n",
       "      <td>21500.983991</td>\n",
       "      <td>22182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acc_y_max</td>\n",
       "      <td>1615.059367</td>\n",
       "      <td>22074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>acc_time_diff_min</td>\n",
       "      <td>2516.145097</td>\n",
       "      <td>21670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>accg_max</td>\n",
       "      <td>1390.769687</td>\n",
       "      <td>20832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acc_x_max</td>\n",
       "      <td>1330.204382</td>\n",
       "      <td>19226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc_x_min</td>\n",
       "      <td>1200.697379</td>\n",
       "      <td>19216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>acc_z_std</td>\n",
       "      <td>2249.194533</td>\n",
       "      <td>19036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>acc_z_min</td>\n",
       "      <td>1399.548385</td>\n",
       "      <td>18962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acc_y_min</td>\n",
       "      <td>2170.755147</td>\n",
       "      <td>18832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>accg_std</td>\n",
       "      <td>2149.129585</td>\n",
       "      <td>18694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>acc_std</td>\n",
       "      <td>1769.210481</td>\n",
       "      <td>18140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>acc_z_max</td>\n",
       "      <td>1098.797518</td>\n",
       "      <td>16238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>acc_mean</td>\n",
       "      <td>3535.606403</td>\n",
       "      <td>15528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>acc_max</td>\n",
       "      <td>1020.279545</td>\n",
       "      <td>12724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feat          gain  split\n",
       "50    acc_time_diff_mean   9295.477116  61650\n",
       "52     acc_time_diff_std   9191.420281  55302\n",
       "44             accg_mean  10343.408568  55282\n",
       "19            acc_xg_max  12991.348483  49244\n",
       "8             acc_y_mean   7475.683666  49096\n",
       "45           accg_median   5570.337669  48658\n",
       "53    acc_time_diff_skew   4185.690966  47266\n",
       "18            acc_xg_min  12235.218745  46896\n",
       "24            acc_yg_min  18269.388275  46142\n",
       "25            acc_yg_max  25294.949096  43494\n",
       "20           acc_xg_mean  10029.531011  43220\n",
       "2             acc_x_mean   2935.989707  41928\n",
       "14            acc_z_mean   4657.786486  41552\n",
       "29           acc_yg_skew   1883.434089  40960\n",
       "30            acc_zg_min  20565.018749  40450\n",
       "32           acc_zg_mean  11904.538372  40356\n",
       "23           acc_xg_skew   1647.632569  39798\n",
       "11            acc_y_skew   1789.968968  39762\n",
       "41              acc_skew   2048.933993  39436\n",
       "21         acc_xg_median   6733.662942  39244\n",
       "5             acc_x_skew   1649.033498  38522\n",
       "26           acc_yg_mean  11198.818746  36524\n",
       "28            acc_yg_std   4705.164250  36476\n",
       "33         acc_zg_median   7952.690118  35940\n",
       "17            acc_z_skew   1523.438171  34938\n",
       "35           acc_zg_skew   1545.995932  33856\n",
       "22            acc_xg_std   6195.305458  33450\n",
       "27         acc_yg_median   9494.822946  32826\n",
       "10             acc_y_std   8220.647170  32564\n",
       "36               acc_min   8333.772215  32476\n",
       "47             accg_skew   1374.817968  31488\n",
       "31            acc_zg_max   8286.295207  31240\n",
       "49     acc_time_diff_max   5291.183610  30740\n",
       "9           acc_y_median   3508.421298  27302\n",
       "4              acc_x_std   9501.445653  26746\n",
       "42              accg_min   2081.491659  26096\n",
       "3           acc_x_median   1696.419379  25382\n",
       "15          acc_z_median   1743.562625  24588\n",
       "39            acc_median   9867.624252  24508\n",
       "51  acc_time_diff_median   6097.832098  22692\n",
       "34            acc_zg_std  21500.983991  22182\n",
       "7              acc_y_max   1615.059367  22074\n",
       "48     acc_time_diff_min   2516.145097  21670\n",
       "43              accg_max   1390.769687  20832\n",
       "1              acc_x_max   1330.204382  19226\n",
       "0              acc_x_min   1200.697379  19216\n",
       "16             acc_z_std   2249.194533  19036\n",
       "12             acc_z_min   1399.548385  18962\n",
       "6              acc_y_min   2170.755147  18832\n",
       "46              accg_std   2149.129585  18694\n",
       "40               acc_std   1769.210481  18140\n",
       "13             acc_z_max   1098.797518  16238\n",
       "38              acc_mean   3535.606403  15528\n",
       "37               acc_max   1020.279545  12724"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp['gain'] = imp[[f for f in imp.columns if 'gain' in f]].sum(axis=1)/folds\n",
    "imp['split'] = imp[[f for f in imp.columns if 'split' in f]].sum(axis=1)\n",
    "imp = imp.sort_values(by=['gain'], ascending=False)\n",
    "imp[['feat', 'gain', 'split']]\n",
    "imp = imp.sort_values(by=['split'], ascending=False)\n",
    "imp[['feat', 'gain', 'split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_combo(y, y_pred):\n",
    "    # 数值ID与行为编码的对应关系\n",
    "    mapping = {\n",
    "        '0': 'A_1', '1': 'B_2', '2': 'A_3', '3': 'A_4', '4': 'B_3', '5': 'C_5', '6': 'C_2', '7': 'A_5', '8': 'B_1', \n",
    "        '9': 'C_1', '10': 'A_2', '11': 'C_3', '12': 'B_5', '13': 'B_4', '14': 'C_4', \n",
    "        '15': 'D_6', '16': 'E_7', '17': 'F_8', '18': 'G_9', '19': 'H_0'\n",
    "              }\n",
    "    # 将行为ID转为编码\n",
    "    code_y, code_y_pred = mapping[str(int(y))], mapping[str(int(y_pred))]\n",
    "    if code_y == code_y_pred: #编码完全相同得分1.0\n",
    "        return 1.0\n",
    "    elif code_y.split(\"_\")[0] == code_y_pred.split(\"_\")[0]: #编码仅字母部分相同得分1.0/7\n",
    "        return 1.0/7\n",
    "    elif code_y.split(\"_\")[1] == code_y_pred.split(\"_\")[1]: #编码仅数字部分相同得分1.0/3\n",
    "        return 1.0/3\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80813\n",
      "0.8312\n"
     ]
    }
   ],
   "source": [
    "labels = np.argmax(preds, axis=1)\n",
    "oof_y = np.argmax(oof_train, axis=1)\n",
    "print(round(accuracy_score(train_y, oof_y), 5))\n",
    "score = sum(acc_combo(y_true, y_pred) for y_true, y_pred in zip(train_y, oof_y)) / oof_y.shape[0]\n",
    "print(round(score, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f41bd39a050>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f41bd2cadd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub = pd.read_csv(root_path+'submit_example.csv')\n",
    "\n",
    "sub['behavior_id'] = labels\n",
    "\n",
    "vc = data_train['behavior_id'].value_counts().sort_index()\n",
    "sns.barplot(vc.index, vc.values)\n",
    "plt.show()\n",
    "vc = sub['behavior_id'].value_counts().sort_index()\n",
    "sns.barplot(vc.index, vc.values)\n",
    "plt.show()\n",
    "sub.to_csv('LGB%.5f.csv' % score, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
